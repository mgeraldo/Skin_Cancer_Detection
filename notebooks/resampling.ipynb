{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45235ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import math\n",
    "from PIL import Image\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe1ca387",
   "metadata": {},
   "outputs": [],
   "source": [
    "isic_train = pd.read_csv('../datasets/ISIC_2019_Training_GroundTruth.csv')\n",
    "\n",
    "\n",
    "id_col = 'image'  # Assuming 'image' is the ID column\n",
    "category_cols = [col for col in isic_train.columns if col != id_col]\n",
    "\n",
    "isic_train_unpivoted = pd.melt(\n",
    "    isic_train,\n",
    "    id_vars=[id_col],\n",
    "    value_vars=category_cols,\n",
    "    var_name='category',\n",
    "    value_name='present'\n",
    ")\n",
    "isic_train_unpivoted = isic_train_unpivoted[isic_train_unpivoted['present'] == 1]\n",
    "isic_train_unpivoted = isic_train_unpivoted.drop(columns=['present'])\n",
    "isic_train_unpivoted.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "AMOUNT_TO_TAKE = {\n",
    "    \"NV\": 1000, \n",
    "    \"MEL\": 1000, \n",
    "    \"BCC\": 1000, \n",
    "    \"BKL\": 1000, \n",
    "    \"AK\": 1000, \n",
    "    \"SCC\": 1000, \n",
    "    \"VASC\": 1000, \n",
    "    \"DF\": 1000\n",
    "}\n",
    "\n",
    "ORDER_OF_OPERATIONS = [\n",
    "    'rot0',\n",
    "    'rot90', \n",
    "    'rot180', \n",
    "    'rot270', \n",
    "    'flipud', \n",
    "    'fliplr'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a312648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img, augmentations=['rot90', 'rot180', 'rot270', 'flipud', 'fliplr'], do_crop=True):\n",
    "    # Preprocessing steps:\n",
    "    # 1. Crop the image to square dimensions\n",
    "    # 2. Determine number of transformations needed. First 3 will be rotations, then the next 2 will be flips \n",
    "\n",
    "    if do_crop:\n",
    "        height, width = img.shape[:2]\n",
    "        min_dim = min(height, width)\n",
    "        start_x = (width - min_dim) // 2\n",
    "        start_y = (height - min_dim) // 2\n",
    "        cropped_img = img[start_y:start_y + min_dim, start_x:start_x + min_dim]\n",
    "    else:\n",
    "        cropped_img = img\n",
    "\n",
    "    augmented_samples = []\n",
    "    if 'rot0' in augmentations:\n",
    "        augmented_samples.append(cropped_img)\n",
    "    if 'rot90' in augmentations:\n",
    "        augmented_samples.append(np.rot90(cropped_img, k=1, axes=(0, 1)))\n",
    "    if 'rot180' in augmentations:\n",
    "        augmented_samples.append(np.rot90(cropped_img, k=2, axes=(0, 1)))\n",
    "    if 'rot270' in augmentations:\n",
    "        augmented_samples.append(np.rot90(cropped_img, k=3, axes=(0, 1)))\n",
    "    if 'flipud' in augmentations:\n",
    "        augmented_samples.append(np.flipud(cropped_img))\n",
    "    if 'fliplr' in augmentations:\n",
    "        augmented_samples.append(np.fliplr(cropped_img))\n",
    "    \n",
    "    return augmented_samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6f566fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing categories:   0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: MEL\n",
      "Available images: 4522, Target: 1000\n",
      "Downsampling to 1000 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving MEL images: 100%|██████████| 1000/1000 [00:22<00:00, 43.51it/s]\n",
      "Processing categories:  12%|█▎        | 1/8 [00:22<02:40, 22.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: NV\n",
      "Available images: 12875, Target: 1000\n",
      "Downsampling to 1000 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving NV images: 100%|██████████| 1000/1000 [00:18<00:00, 55.52it/s]\n",
      "Processing categories:  25%|██▌       | 2/8 [00:41<02:00, 20.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: BCC\n",
      "Available images: 3323, Target: 1000\n",
      "Downsampling to 1000 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving BCC images: 100%|██████████| 1000/1000 [00:24<00:00, 40.46it/s]\n",
      "Processing categories:  38%|███▊      | 3/8 [01:05<01:50, 22.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: AK\n",
      "Available images: 867, Target: 1000\n",
      "Need augmentation: 867 available, need 133 more\n",
      "Using augmentations: ['rot0', 'rot90']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing original AK images: 867it [00:20, 41.64it/s]\n",
      "Augmenting with rot90: 100%|██████████| 867/867 [00:19<00:00, 45.26it/s]\n",
      "Processing categories:  50%|█████     | 4/8 [01:45<01:56, 29.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: BKL\n",
      "Available images: 2624, Target: 1000\n",
      "Downsampling to 1000 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving BKL images: 100%|██████████| 1000/1000 [00:19<00:00, 52.13it/s]\n",
      "Processing categories:  62%|██████▎   | 5/8 [02:04<01:16, 25.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: DF\n",
      "Available images: 239, Target: 1000\n",
      "Need augmentation: 239 available, need 761 more\n",
      "Using augmentations: ['rot0', 'rot90', 'rot180', 'rot270', 'flipud']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing original DF images: 239it [00:04, 50.67it/s]\n",
      "Augmenting with rot90: 100%|██████████| 239/239 [00:03<00:00, 64.45it/s]\n",
      "Augmenting with rot180: 100%|██████████| 239/239 [00:03<00:00, 67.62it/s]\n",
      "Augmenting with rot270: 100%|██████████| 239/239 [00:03<00:00, 66.84it/s]\n",
      "Augmenting with flipud: 100%|██████████| 239/239 [00:03<00:00, 66.03it/s]\n",
      "Processing categories:  75%|███████▌  | 6/8 [02:24<00:46, 23.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: VASC\n",
      "Available images: 253, Target: 1000\n",
      "Need augmentation: 253 available, need 747 more\n",
      "Using augmentations: ['rot0', 'rot90', 'rot180', 'rot270']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing original VASC images: 253it [00:04, 52.67it/s]\n",
      "Augmenting with rot90: 100%|██████████| 253/253 [00:03<00:00, 70.21it/s]\n",
      "Augmenting with rot180: 100%|██████████| 253/253 [00:03<00:00, 71.81it/s]\n",
      "Augmenting with rot270: 100%|██████████| 253/253 [00:03<00:00, 73.06it/s]\n",
      "Processing categories:  88%|████████▊ | 7/8 [02:39<00:20, 20.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing category: SCC\n",
      "Available images: 628, Target: 1000\n",
      "Need augmentation: 628 available, need 372 more\n",
      "Using augmentations: ['rot0', 'rot90']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing original SCC images: 628it [00:13, 45.44it/s]\n",
      "Augmenting with rot90: 100%|██████████| 628/628 [00:12<00:00, 52.33it/s]\n",
      "Processing categories: 100%|██████████| 8/8 [03:05<00:00, 23.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final dataset contains 8000 images\n",
      "category\n",
      "MEL     1000\n",
      "NV      1000\n",
      "BCC     1000\n",
      "AK      1000\n",
      "BKL     1000\n",
      "DF      1000\n",
      "VASC    1000\n",
      "SCC     1000\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Clear previous variable definitions\n",
    "augmented_data = []\n",
    "INPUT_DIRECTORY = '../datasets/ISIC_2019_Training/'\n",
    "OUTPUT_DIRECTORY = '../datasets/ISIC_2019_cleaned/'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIRECTORY, exist_ok=True)\n",
    "\n",
    "# Track our resampled dataset\n",
    "final_dataset = []\n",
    "\n",
    "# Process each category\n",
    "for category in tqdm(isic_train_unpivoted['category'].unique(), desc=\"Processing categories\"):\n",
    "    if category not in AMOUNT_TO_TAKE:\n",
    "        continue\n",
    "        \n",
    "    target_count = AMOUNT_TO_TAKE[category]\n",
    "    category_df = isic_train_unpivoted[isic_train_unpivoted['category'] == category]\n",
    "    available_count = len(category_df)\n",
    "    \n",
    "    print(f\"\\nProcessing category: {category}\")\n",
    "    print(f\"Available images: {available_count}, Target: {target_count}\")\n",
    "    \n",
    "    # Case 1: We have enough images, downsample to target count\n",
    "    if available_count >= target_count:\n",
    "        print(f\"Downsampling to {target_count} images\")\n",
    "        sampled_df = category_df.sample(n=target_count, random_state=42)\n",
    "        \n",
    "        # Process and save original images\n",
    "        for _, row in tqdm(sampled_df.iterrows(), desc=f\"Saving {category} images\", total=len(sampled_df)):\n",
    "            img_path = f'{INPUT_DIRECTORY}{row[\"image\"]}.jpg'\n",
    "            img = np.array(Image.open(img_path))\n",
    "            processed_img = preprocess_image(img, augmentations=['rot0'], do_crop=True)[0]\n",
    "            \n",
    "            output_filename = f'{row[\"image\"]}_preprocessed_rot0.jpg'\n",
    "            output_path = f'{OUTPUT_DIRECTORY}{output_filename}'\n",
    "            Image.fromarray(processed_img).save(output_path)\n",
    "            \n",
    "            final_dataset.append({\n",
    "                'image': output_filename,\n",
    "                'category': category,\n",
    "                'augmentation_method': 'rot0'\n",
    "            })\n",
    "            \n",
    "    # Case 2: We need to augment to reach target count\n",
    "    else:\n",
    "        print(f\"Need augmentation: {available_count} available, need {target_count - available_count} more\")\n",
    "        \n",
    "        # Calculate how many augmentation methods we need\n",
    "        needed_count = target_count - available_count\n",
    "        augmentations_needed = math.ceil(needed_count / available_count)\n",
    "        \n",
    "        # Get the augmentation methods we'll use\n",
    "        augmentation_methods = ORDER_OF_OPERATIONS[:min(augmentations_needed + 1, len(ORDER_OF_OPERATIONS))]\n",
    "        print(f\"Using augmentations: {augmentation_methods}\")\n",
    "        \n",
    "        # First, process all original images\n",
    "        original_images = []\n",
    "        for _, row in tqdm(category_df.iterrows(), desc=f\"Processing original {category} images\"):\n",
    "            img_path = f'{INPUT_DIRECTORY}{row[\"image\"]}.jpg'\n",
    "            img = np.array(Image.open(img_path))\n",
    "            processed_img = preprocess_image(img, augmentations=['rot0'], do_crop=True)[0]\n",
    "            \n",
    "            output_filename = f'{row[\"image\"]}_preprocessed_rot0.jpg'\n",
    "            output_path = f'{OUTPUT_DIRECTORY}{output_filename}'\n",
    "            Image.fromarray(processed_img).save(output_path)\n",
    "            \n",
    "            final_dataset.append({\n",
    "                'image': output_filename,\n",
    "                'category': category,\n",
    "                'augmentation_method': 'rot0'\n",
    "            })\n",
    "            \n",
    "            # Also add this image to our augmentation candidates\n",
    "            original_images.append({\n",
    "                'image_id': row[\"image\"],\n",
    "                'img_array': img\n",
    "            })\n",
    "        \n",
    "        # Now create augmented images\n",
    "        augmented_candidates = []\n",
    "        \n",
    "        # Skip 'rot0' since we already used it for originals\n",
    "        for aug_method in augmentation_methods[1:]:\n",
    "            for img_data in tqdm(original_images, desc=f\"Augmenting with {aug_method}\"):\n",
    "                img = img_data['img_array']\n",
    "                image_id = img_data['image_id']\n",
    "                \n",
    "                processed_imgs = preprocess_image(img, augmentations=[aug_method], do_crop=True)\n",
    "                \n",
    "                if processed_imgs:  # Make sure we have results\n",
    "                    output_filename = f'{image_id}_preprocessed_{aug_method}.jpg'\n",
    "                    output_path = f'{OUTPUT_DIRECTORY}{output_filename}'\n",
    "                    Image.fromarray(processed_imgs[0]).save(output_path)\n",
    "                    \n",
    "                    augmented_candidates.append({\n",
    "                        'image': output_filename,\n",
    "                        'category': category,\n",
    "                        'augmentation_method': aug_method\n",
    "                    })\n",
    "        \n",
    "        # Sample the needed number of augmented images\n",
    "        if augmented_candidates:\n",
    "            augmented_df = pd.DataFrame(augmented_candidates)\n",
    "            \n",
    "            # If we have more augmented images than needed, sample down\n",
    "            if len(augmented_df) > needed_count:\n",
    "                augmented_df = augmented_df.sample(n=needed_count, random_state=42)\n",
    "            \n",
    "            # Add the sampled augmented images to our final dataset\n",
    "            final_dataset.extend(augmented_df.to_dict('records'))\n",
    "\n",
    "# Convert to DataFrame\n",
    "final_df = pd.DataFrame(final_dataset)\n",
    "print(f\"\\nFinal dataset contains {len(final_df)} images\")\n",
    "print(final_df['category'].value_counts())\n",
    "\n",
    "# Save metadata\n",
    "final_df.to_csv(f'{OUTPUT_DIRECTORY}resampled_metadata.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747d67f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

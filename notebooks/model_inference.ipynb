{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38a08787",
   "metadata": {},
   "source": [
    "# EfficientNet-B3 Skin Lesion Classification - Inference Only\n",
    "\n",
    "This notebook loads pre-trained models and performs inference on skin lesion images.\n",
    "\n",
    "## Features:\n",
    "- Load pre-trained EfficientNet-B3 checkpoints\n",
    "- Perform batch inference on test datasets\n",
    "- Single image prediction\n",
    "- Comprehensive evaluation metrics\n",
    "- No training required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "94a3f0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Setup complete for inference!\n"
     ]
    }
   ],
   "source": [
    "# Essential imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Add scripts directory to path\n",
    "sys.path.append('../scripts')\n",
    "from data_loader import AzureBlobLoader\n",
    "from image_preprocessor import ImagePreprocessor\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "print(\"Setup complete for inference!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "73c4145d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded for inference:\n",
      "  images_dir: ../pipeline_output/images\n",
      "  metadata_file: ../pipeline_output/data/metadata/isic_2019_preprocessed.csv\n",
      "  batch_size: 16\n",
      "  num_workers: 0\n",
      "  image_size: 224\n",
      "  num_classes: 8\n",
      "  class_names: ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC']\n",
      "\n",
      "Available models:\n",
      "  0: âœ“ models/efficientnet_b3_skinlesion_inference_20250729_205914.pth\n",
      "  1: âœ“ models/vgg16_skinlesion_best_model.pth\n",
      "  2: âœ“ models/vgg16_skinlesion_inference_20250728_142515.pth\n"
     ]
    }
   ],
   "source": [
    "# Configuration for inference\n",
    "CONFIG = {\n",
    "    'images_dir': '../pipeline_output/images',\n",
    "    'metadata_file': '../pipeline_output/data/metadata/isic_2019_preprocessed.csv',\n",
    "    'batch_size': 16,\n",
    "    'num_workers': 0,\n",
    "    'image_size': 224,\n",
    "    'num_classes': 8,\n",
    "    'class_names': ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC'],\n",
    "    \n",
    "    # Available pre-trained models\n",
    "    'available_models': [\n",
    "        \"models/efficientnet_b3_skinlesion_inference_20250729_205914.pth\",\n",
    "        \"models/vgg16_skinlesion_best_model.pth\",\n",
    "        \"models/vgg16_skinlesion_inference_20250728_142515.pth\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded for inference:\")\n",
    "for key, value in CONFIG.items():\n",
    "    if key != 'available_models':\n",
    "        print(f\"  {key}: {value}\")\n",
    "        \n",
    "print(f\"\\nAvailable models:\")\n",
    "for i, model_path in enumerate(CONFIG['available_models']):\n",
    "    exists = \"âœ“\" if os.path.exists(model_path) else \"âœ—\"\n",
    "    print(f\"  {i}: {exists} {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "39d4bcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated EfficientNet-B3 model architecture defined with feature_extractor!\n"
     ]
    }
   ],
   "source": [
    "# Updated EfficientNet model definition to match the training notebook\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "\n",
    "class EfficientNetB3SkinLesionClassifier(nn.Module):\n",
    "    \"\"\"EfficientNet-B3 based transfer learning model for skin lesion classification\"\"\"\n",
    "\n",
    "    def __init__(self, num_classes=8, pretrained=True, freeze_backbone=True):\n",
    "        super(EfficientNetB3SkinLesionClassifier, self).__init__()\n",
    "\n",
    "        # Store num_classes as a class attribute\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Load pretrained EfficientNet-B3\n",
    "        self.efficientnet = EfficientNet.from_pretrained('efficientnet-b3') if pretrained else EfficientNet.from_name('efficientnet-b3')\n",
    "\n",
    "        # Freeze backbone if requested\n",
    "        if freeze_backbone:\n",
    "            for param in self.efficientnet.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "        # Get the number of features from the classifier\n",
    "        num_features = self.efficientnet._fc.in_features\n",
    "\n",
    "        # Replace the classifier\n",
    "        self.efficientnet._fc = nn.Sequential(\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(num_features, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "        # Create feature extractor (needed for compatibility with saved models)\n",
    "        self.feature_extractor = nn.Sequential(*list(self.efficientnet.children())[:-1])\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.efficientnet(x)\n",
    "\n",
    "    def unfreeze_backbone(self):\n",
    "        \"\"\"Unfreeze the backbone for fine-tuning\"\"\"\n",
    "        for param in self.efficientnet.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(\"EfficientNet-B3 backbone unfrozen for fine-tuning\")\n",
    "\n",
    "    def extract_features(self, x):\n",
    "        \"\"\"Extract penultimate layer features (before final classifier)\"\"\"\n",
    "        # Use the EfficientNet's built-in extract_features method\n",
    "        return self.efficientnet.extract_features(x)\n",
    "\n",
    "print(\"Updated EfficientNet-B3 model architecture defined with feature_extractor!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0b2e772c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference transforms defined!\n"
     ]
    }
   ],
   "source": [
    "# Transforms for inference\n",
    "inference_transforms = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Inference transforms defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ab32ebfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loading function defined!\n"
     ]
    }
   ],
   "source": [
    "def load_pretrained_model(checkpoint_path, device, config=None):\n",
    "    \"\"\"\n",
    "    Load a pre-trained EfficientNet-B3 model from checkpoint\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the .pth checkpoint file\n",
    "        device: torch device to load model on\n",
    "        config: Optional config dict, uses global CONFIG if None\n",
    "    \n",
    "    Returns:\n",
    "        model: Loaded model ready for inference\n",
    "        checkpoint_info: Dictionary with checkpoint metadata\n",
    "    \"\"\"\n",
    "    if config is None:\n",
    "        config = CONFIG\n",
    "    \n",
    "    print(f\"Loading pre-trained model from: {checkpoint_path}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "    \n",
    "    # Create model with correct architecture\n",
    "    model = EfficientNetB3SkinLesionClassifier(\n",
    "        num_classes=checkpoint.get('num_classes', config['num_classes']),\n",
    "        pretrained=False,  # We're loading pre-trained weights\n",
    "        freeze_backbone=False  # For inference, backbone should be unfrozen\n",
    "    )\n",
    "    \n",
    "    # Load the state dict\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model = model.to(device)\n",
    "    model.eval()  # Set to evaluation mode\n",
    "    \n",
    "    # Extract checkpoint info\n",
    "    checkpoint_info = {\n",
    "        'model_type': checkpoint.get('model_type', 'Unknown'),\n",
    "        'export_timestamp': checkpoint.get('export_timestamp', 'Unknown'),\n",
    "        'num_classes': checkpoint.get('num_classes', config['num_classes']),\n",
    "        'class_names': checkpoint.get('class_names', config['class_names']),\n",
    "        'image_size': checkpoint.get('image_size', config['image_size']),\n",
    "        'transforms': checkpoint.get('transforms', {\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225]\n",
    "        })\n",
    "    }\n",
    "    \n",
    "    print(f\"âœ“ Model loaded successfully!\")\n",
    "    print(f\"   Model type: {checkpoint_info['model_type']}\")\n",
    "    print(f\"   Classes: {checkpoint_info['num_classes']}\")\n",
    "    print(f\"   Export time: {checkpoint_info['export_timestamp']}\")\n",
    "    \n",
    "    return model, checkpoint_info\n",
    "\n",
    "print(\"Model loading function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "dd880bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model from: models/efficientnet_b3_skinlesion_inference_20250729_205914.pth\n",
      "âœ“ Model loaded successfully!\n",
      "   Model type: EfficientNetB3SkinLesionClassifier\n",
      "   Classes: 8\n",
      "   Export time: 2025-07-29T20:59:14.185525\n",
      "\n",
      "Model ready for inference!\n",
      "Total parameters: 11,488,304\n",
      "âœ“ Model loaded successfully!\n",
      "   Model type: EfficientNetB3SkinLesionClassifier\n",
      "   Classes: 8\n",
      "   Export time: 2025-07-29T20:59:14.185525\n",
      "\n",
      "Model ready for inference!\n",
      "Total parameters: 11,488,304\n"
     ]
    }
   ],
   "source": [
    "# Load the EfficientNet-B3 model\n",
    "checkpoint_path = CONFIG['available_models'][0]  # EfficientNet-B3 model\n",
    "\n",
    "try:\n",
    "    model, checkpoint_info = load_pretrained_model(checkpoint_path, device, CONFIG)\n",
    "    print(f\"\\nModel ready for inference!\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Please check that the model file exists and is compatible.\")\n",
    "    model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "002d0b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single image prediction function defined!\n"
     ]
    }
   ],
   "source": [
    "def predict_single_image(model, image_path, transforms, device, class_names):\n",
    "    \"\"\"\n",
    "    Predict class for a single image\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model\n",
    "        image_path: Path to image file\n",
    "        transforms: Preprocessing transforms\n",
    "        device: torch device\n",
    "        class_names: List of class names\n",
    "    \n",
    "    Returns:\n",
    "        prediction_dict: Dictionary with prediction results\n",
    "    \"\"\"\n",
    "    # Load and preprocess image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transforms(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image_tensor)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        confidence, predicted = torch.max(probabilities, 1)\n",
    "        \n",
    "        # Get top 3 predictions\n",
    "        top3_probs, top3_indices = torch.topk(probabilities[0], 3)\n",
    "        \n",
    "        prediction_dict = {\n",
    "            'predicted_class': class_names[predicted.item()],\n",
    "            'confidence': confidence.item(),\n",
    "            'predicted_index': predicted.item(),\n",
    "            'top3_predictions': [\n",
    "                {\n",
    "                    'class': class_names[idx.item()],\n",
    "                    'probability': prob.item()\n",
    "                }\n",
    "                for prob, idx in zip(top3_probs, top3_indices)\n",
    "            ],\n",
    "            'all_probabilities': probabilities[0].cpu().numpy()\n",
    "        }\n",
    "    \n",
    "    return prediction_dict\n",
    "\n",
    "print(\"Single image prediction function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "da6215d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single image predictions:\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Test single image prediction\n",
    "if model is not None:\n",
    "    # Find a sample image to test\n",
    "    sample_images = [f for f in os.listdir(CONFIG['images_dir']) if f.endswith('.jpg')][:5]\n",
    "    \n",
    "    print(\"Testing single image predictions:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i, image_file in enumerate(sample_images):\n",
    "        image_path = os.path.join(CONFIG['images_dir'], image_file)\n",
    "        \n",
    "        try:\n",
    "            result = predict_single_image(\n",
    "                model, image_path, inference_transforms, device, CONFIG['class_names']\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nImage {i+1}: {image_file}\")\n",
    "            print(f\"   Prediction: {result['predicted_class']} ({result['confidence']:.3f} confidence)\")\n",
    "            print(f\"   Top 3 predictions:\")\n",
    "            for j, pred in enumerate(result['top3_predictions']):\n",
    "                print(f\"      {j+1}. {pred['class']}: {pred['probability']:.3f}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_file}: {e}\")\n",
    "            \n",
    "        if i >= 2:  # Limit to first 3 images for demo\n",
    "            break\n",
    "else:\n",
    "    print(\"Model not loaded - cannot perform predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c2986144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch inference on test datasets:\n",
      "1. Load your test dataset using the SkinLesionDataset class\n",
      "2. Create a DataLoader\n",
      "3. Run the comprehensive evaluation from the training notebook\n",
      "\n",
      "Example code:\n",
      "\n",
      "# Load test data\n",
      "test_df = pd.read_csv('your_test_metadata.csv')\n",
      "test_dataset = SkinLesionDataset(test_df, CONFIG['images_dir'], inference_transforms)\n",
      "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
      "\n",
      "# Run evaluation\n",
      "evaluation_results = evaluate_model_comprehensive(model, test_loader, device, CONFIG['class_names'])\n",
      "\n",
      "ğŸš€ Feature Extraction from Preprocessed Dataset\n",
      "============================================================\n",
      "PreprocessedFeatureDataset class defined!\n"
     ]
    }
   ],
   "source": [
    "# If you want to run batch inference on a dataset, load your test data here\n",
    "# This section is optional and requires your dataset setup\n",
    "\n",
    "print(\"For batch inference on test datasets:\")\n",
    "print(\"1. Load your test dataset using the SkinLesionDataset class\")\n",
    "print(\"2. Create a DataLoader\")\n",
    "print(\"3. Run the comprehensive evaluation from the training notebook\")\n",
    "print(\"\")\n",
    "print(\"Example code:\")\n",
    "print(\"\"\"\n",
    "# Load test data\n",
    "test_df = pd.read_csv('your_test_metadata.csv')\n",
    "test_dataset = SkinLesionDataset(test_df, CONFIG['images_dir'], inference_transforms)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False)\n",
    "\n",
    "# Run evaluation\n",
    "evaluation_results = evaluate_model_comprehensive(model, test_loader, device, CONFIG['class_names'])\n",
    "\"\"\")\n",
    "\n",
    "# Feature extraction from preprocessed dataset\n",
    "# Load the full dataset and extract penultimate layer features\n",
    "\n",
    "print(\"ğŸš€ Feature Extraction from Preprocessed Dataset\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Dataset class for loading preprocessed images\n",
    "class PreprocessedFeatureDataset(Dataset):\n",
    "    \"\"\"Simple dataset for feature extraction from preprocessed images\"\"\"\n",
    "    \n",
    "    def __init__(self, metadata_df, transform=None):\n",
    "        self.metadata_df = metadata_df.copy().reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "        print(f\"Dataset initialized with {len(self.metadata_df)} images\")\n",
    "        if 'label' in self.metadata_df.columns:\n",
    "            print(f\"Class distribution:\")\n",
    "            print(self.metadata_df['label'].value_counts())\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.metadata_df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.metadata_df.iloc[idx]\n",
    "        image_path = row['local_path']\n",
    "        \n",
    "        # Load image\n",
    "        try:\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {image_path}: {e}\")\n",
    "            # Return black image as fallback\n",
    "            image = Image.new('RGB', (224, 224), color='black')\n",
    "        \n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, idx  # Return index to track which row this corresponds to\n",
    "\n",
    "print(\"PreprocessedFeatureDataset class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "4e96fba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction function defined!\n"
     ]
    }
   ],
   "source": [
    "def extract_features_from_model(model, dataloader, device, feature_dim=1536):\n",
    "    \"\"\"\n",
    "    Extract penultimate layer features from EfficientNet model\n",
    "    \n",
    "    Args:\n",
    "        model: EfficientNet model\n",
    "        dataloader: DataLoader with preprocessed images\n",
    "        device: torch device\n",
    "        feature_dim: Expected feature dimension (1536 for EfficientNet-B3)\n",
    "    \n",
    "    Returns:\n",
    "        features: numpy array of shape (num_samples, feature_dim)\n",
    "        indices: list of indices corresponding to dataframe rows\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_features = []\n",
    "    all_indices = []\n",
    "    \n",
    "    print(f\"Extracting features from {len(dataloader)} batches...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, indices) in enumerate(dataloader):\n",
    "            if batch_idx % 20 == 0:\n",
    "                print(f\"Processing batch {batch_idx+1}/{len(dataloader)}\")\n",
    "            \n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Extract features using the feature_extractor method\n",
    "            features = model.extract_features(images)\n",
    "            \n",
    "            # Global average pooling to get fixed-size features\n",
    "            features = F.adaptive_avg_pool2d(features, (1, 1))\n",
    "            features = features.view(features.size(0), -1)  # Flatten\n",
    "            \n",
    "            all_features.append(features.cpu().numpy())\n",
    "            all_indices.extend(indices.numpy().tolist())\n",
    "    \n",
    "    # Concatenate all features\n",
    "    features_array = np.concatenate(all_features, axis=0)\n",
    "    \n",
    "    print(f\"âœ“ Feature extraction completed!\")\n",
    "    print(f\"Feature shape: {features_array.shape}\")\n",
    "    \n",
    "    return features_array, all_indices\n",
    "\n",
    "print(\"Feature extraction function defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72cfd797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c47f84d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting EfficientNet Feature Extraction Pipeline\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Dataset Configuration:\n",
      "   Metadata: ../pipeline_output/data/metadata/isic_2019_preprocessed.csv\n",
      "   Images: ../pipeline_output/images/processed/isic_2019\n",
      "âœ“ Found all required files\n",
      "\n",
      "ğŸ“‹ Loaded 8000 records from metadata\n",
      "   Columns: ['original_image', 'processed_image', 'local_path', 'label', 'augmentation', 'width', 'height']\n",
      "\n",
      "ğŸ” Verifying image files...\n",
      "âœ“ All 8000 images found\n",
      "\n",
      "ğŸ”§ Creating dataset for feature extraction...\n",
      "âœ“ Dataset created: 8000 images, 500 batches\n",
      "\n",
      "ğŸ§  Extracting EfficientNet features...\n",
      "   This may take several minutes for 8000 images\n",
      "âœ“ All 8000 images found\n",
      "\n",
      "ğŸ”§ Creating dataset for feature extraction...\n",
      "âœ“ Dataset created: 8000 images, 500 batches\n",
      "\n",
      "ğŸ§  Extracting EfficientNet features...\n",
      "   This may take several minutes for 8000 images\n",
      "   Processing batch 1/500 (0.2%)\n",
      "   Processing batch 1/500 (0.2%)\n",
      "   Processing batch 51/500 (10.2%)\n",
      "   Processing batch 51/500 (10.2%)\n",
      "   Processing batch 101/500 (20.2%)\n",
      "   Processing batch 101/500 (20.2%)\n",
      "   Processing batch 151/500 (30.2%)\n",
      "   Processing batch 151/500 (30.2%)\n",
      "   Processing batch 201/500 (40.2%)\n",
      "   Processing batch 201/500 (40.2%)\n",
      "   Processing batch 251/500 (50.2%)\n",
      "   Processing batch 251/500 (50.2%)\n",
      "   Processing batch 301/500 (60.2%)\n",
      "   Processing batch 301/500 (60.2%)\n",
      "   Processing batch 351/500 (70.2%)\n",
      "   Processing batch 351/500 (70.2%)\n",
      "   Processing batch 401/500 (80.2%)\n",
      "   Processing batch 401/500 (80.2%)\n",
      "   Processing batch 451/500 (90.2%)\n",
      "   Processing batch 451/500 (90.2%)\n",
      "\n",
      "âœ… Feature extraction completed!\n",
      "   Processing time: 0:26:34.582124\n",
      "   Features shape: (8000, 1536)\n",
      "   Processing rate: 5.0 images/second\n",
      "\n",
      "ğŸ’¾ Saving EfficientNet features as .npy file...\n",
      "   Output directory: ../pipeline_output/features/final/isic_2019\n",
      "   Features file: efficientnet_features.npy\n",
      "\n",
      "âœ… Successfully saved EfficientNet features!\n",
      "   File: efficientnet_features.npy\n",
      "   Shape: (8000, 1536)\n",
      "   Data type: float32\n",
      "   File size: 46.9 MB\n",
      "   Location: ../pipeline_output/features/final/isic_2019/efficientnet_features.npy\n",
      "\n",
      "ğŸ“ˆ Feature Statistics:\n",
      "   Mean: 0.046781\n",
      "   Std:  0.313201\n",
      "   Min:  -0.270400\n",
      "   Max:  5.420953\n",
      "\n",
      "ğŸ“‹ Metadata saved: efficientnet_features_metadata.json\n",
      "\n",
      "ğŸ¯ EfficientNet Feature Extraction Pipeline Completed!\n",
      "âœ“ 8,000 images processed\n",
      "âœ“ 1,536 features per image\n",
      "âœ“ 12,288,000 total feature values extracted\n",
      "âœ“ Features saved as .npy file (compatible with existing pipeline)\n",
      "âœ“ Ready for downstream ML tasks\n",
      "\n",
      "ğŸ“– Usage Example:\n",
      "```python\n",
      "import numpy as np\n",
      "features = np.load('../pipeline_output/features/final/isic_2019/efficientnet_features.npy')\n",
      "print(f'Loaded features shape: {features.shape}')\n",
      "```\n",
      "\n",
      "âœ… Feature extraction completed!\n",
      "   Processing time: 0:26:34.582124\n",
      "   Features shape: (8000, 1536)\n",
      "   Processing rate: 5.0 images/second\n",
      "\n",
      "ğŸ’¾ Saving EfficientNet features as .npy file...\n",
      "   Output directory: ../pipeline_output/features/final/isic_2019\n",
      "   Features file: efficientnet_features.npy\n",
      "\n",
      "âœ… Successfully saved EfficientNet features!\n",
      "   File: efficientnet_features.npy\n",
      "   Shape: (8000, 1536)\n",
      "   Data type: float32\n",
      "   File size: 46.9 MB\n",
      "   Location: ../pipeline_output/features/final/isic_2019/efficientnet_features.npy\n",
      "\n",
      "ğŸ“ˆ Feature Statistics:\n",
      "   Mean: 0.046781\n",
      "   Std:  0.313201\n",
      "   Min:  -0.270400\n",
      "   Max:  5.420953\n",
      "\n",
      "ğŸ“‹ Metadata saved: efficientnet_features_metadata.json\n",
      "\n",
      "ğŸ¯ EfficientNet Feature Extraction Pipeline Completed!\n",
      "âœ“ 8,000 images processed\n",
      "âœ“ 1,536 features per image\n",
      "âœ“ 12,288,000 total feature values extracted\n",
      "âœ“ Features saved as .npy file (compatible with existing pipeline)\n",
      "âœ“ Ready for downstream ML tasks\n",
      "\n",
      "ğŸ“– Usage Example:\n",
      "```python\n",
      "import numpy as np\n",
      "features = np.load('../pipeline_output/features/final/isic_2019/efficientnet_features.npy')\n",
      "print(f'Loaded features shape: {features.shape}')\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ========================================================================\n",
    "# BATCH INFERENCE PIPELINE FOR EFFICIENTNET FEATURE EXTRACTION\n",
    "# ========================================================================\n",
    "\n",
    "print(\"ğŸš€ Starting EfficientNet Feature Extraction Pipeline\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Verify model is loaded\n",
    "if 'model' not in locals() or model is None:\n",
    "    print(\"âŒ Model not found. Loading model...\")\n",
    "    \n",
    "    # Load the model\n",
    "    checkpoint_path = CONFIG['available_models'][0]  # EfficientNet-B3 model\n",
    "    try:\n",
    "        model, checkpoint_info = load_pretrained_model(checkpoint_path, device, CONFIG)\n",
    "        print(f\"âœ“ Model loaded successfully!\")\n",
    "        print(f\"   Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading model: {e}\")\n",
    "        model = None\n",
    "\n",
    "if model is not None:\n",
    "    # Dataset configuration\n",
    "    metadata_path = \"../pipeline_output/data/metadata/isic_2019_preprocessed.csv\"\n",
    "    images_base_dir = \"../pipeline_output/images/processed/isic_2019\"\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Dataset Configuration:\")\n",
    "    print(f\"   Metadata: {metadata_path}\")\n",
    "    print(f\"   Images: {images_base_dir}\")\n",
    "    \n",
    "    # Check if files exist\n",
    "    if not os.path.exists(metadata_path):\n",
    "        print(f\"âŒ Metadata file not found: {metadata_path}\")\n",
    "    elif not os.path.exists(images_base_dir):\n",
    "        print(f\"âŒ Images directory not found: {images_base_dir}\")\n",
    "    else:\n",
    "        print(f\"âœ“ Found all required files\")\n",
    "        \n",
    "        # Load metadata\n",
    "        try:\n",
    "            df = pd.read_csv(metadata_path)\n",
    "            print(f\"\\nğŸ“‹ Loaded {len(df)} records from metadata\")\n",
    "            print(f\"   Columns: {list(df.columns)}\")\n",
    "            \n",
    "            # Build image paths\n",
    "            if 'processed_image' in df.columns:\n",
    "                df['full_image_path'] = df['processed_image'].apply(\n",
    "                    lambda x: os.path.join(images_base_dir, x)\n",
    "                )\n",
    "            elif 'local_path' in df.columns:\n",
    "                df['full_image_path'] = df['local_path']\n",
    "            else:\n",
    "                print(\"âŒ No image path column found\")\n",
    "                df = None\n",
    "            \n",
    "            if df is not None:\n",
    "                # Check image existence\n",
    "                print(\"\\nğŸ” Verifying image files...\")\n",
    "                valid_mask = df['full_image_path'].apply(os.path.exists)\n",
    "                valid_df = df[valid_mask].copy().reset_index(drop=True)\n",
    "                \n",
    "                missing = len(df) - len(valid_df)\n",
    "                if missing > 0:\n",
    "                    print(f\"âš ï¸  {missing} images missing, proceeding with {len(valid_df)} images\")\n",
    "                else:\n",
    "                    print(f\"âœ“ All {len(valid_df)} images found\")\n",
    "                \n",
    "                if len(valid_df) > 0:\n",
    "                    # Create dataset for feature extraction\n",
    "                    print(f\"\\nğŸ”§ Creating dataset for feature extraction...\")\n",
    "                    \n",
    "                    class FeatureExtractionDataset(Dataset):\n",
    "                        def __init__(self, df, transform=None):\n",
    "                            self.df = df.reset_index(drop=True)\n",
    "                            self.transform = transform\n",
    "                        \n",
    "                        def __len__(self):\n",
    "                            return len(self.df)\n",
    "                        \n",
    "                        def __getitem__(self, idx):\n",
    "                            row = self.df.iloc[idx]\n",
    "                            image_path = row['full_image_path']\n",
    "                            \n",
    "                            try:\n",
    "                                image = Image.open(image_path).convert('RGB')\n",
    "                            except Exception as e:\n",
    "                                print(f\"Warning: Error loading {image_path}: {e}\")\n",
    "                                image = Image.new('RGB', (224, 224), color='black')\n",
    "                            \n",
    "                            if self.transform:\n",
    "                                image = self.transform(image)\n",
    "                            \n",
    "                            return image, idx\n",
    "                    \n",
    "                    # Create dataset and dataloader\n",
    "                    dataset = FeatureExtractionDataset(valid_df, inference_transforms)\n",
    "                    dataloader = DataLoader(\n",
    "                        dataset,\n",
    "                        batch_size=CONFIG['batch_size'],\n",
    "                        shuffle=False,\n",
    "                        num_workers=CONFIG['num_workers'],\n",
    "                        pin_memory=torch.cuda.is_available()\n",
    "                    )\n",
    "                    \n",
    "                    print(f\"âœ“ Dataset created: {len(dataset)} images, {len(dataloader)} batches\")\n",
    "                    \n",
    "                    # Extract features\n",
    "                    print(f\"\\nğŸ§  Extracting EfficientNet features...\")\n",
    "                    print(f\"   This may take several minutes for {len(dataset)} images\")\n",
    "                    \n",
    "                    start_time = datetime.now()\n",
    "                    \n",
    "                    model.eval()\n",
    "                    all_features = []\n",
    "                    all_indices = []\n",
    "                    \n",
    "                    with torch.no_grad():\n",
    "                        for batch_idx, (images, indices) in enumerate(dataloader):\n",
    "                            if batch_idx % 50 == 0:\n",
    "                                print(f\"   Processing batch {batch_idx+1}/{len(dataloader)} ({(batch_idx+1)/len(dataloader)*100:.1f}%)\")\n",
    "                            \n",
    "                            images = images.to(device)\n",
    "                            \n",
    "                            # Extract features using EfficientNet's extract_features method\n",
    "                            features = model.extract_features(images)\n",
    "                            \n",
    "                            # Apply global average pooling\n",
    "                            features = F.adaptive_avg_pool2d(features, (1, 1))\n",
    "                            features = features.view(features.size(0), -1)\n",
    "                            \n",
    "                            all_features.append(features.cpu().numpy())\n",
    "                            all_indices.extend(indices.numpy().tolist())\n",
    "                    \n",
    "                    # Combine all features\n",
    "                    features_array = np.concatenate(all_features, axis=0)\n",
    "                    \n",
    "                    end_time = datetime.now()\n",
    "                    processing_time = end_time - start_time\n",
    "                    \n",
    "                    print(f\"\\nâœ… Feature extraction completed!\")\n",
    "                    print(f\"   Processing time: {processing_time}\")\n",
    "                    print(f\"   Features shape: {features_array.shape}\")\n",
    "                    print(f\"   Processing rate: {len(dataset) / processing_time.total_seconds():.1f} images/second\")\n",
    "                    \n",
    "                    # ========================================================================\n",
    "                    # SAVE FEATURES AS .NPY FILES (FOLLOWING EXISTING PATTERN)\n",
    "                    # ========================================================================\n",
    "                    \n",
    "                    # Prepare output directory\n",
    "                    features_output_dir = \"../pipeline_output/features/final/isic_2019\"\n",
    "                    os.makedirs(features_output_dir, exist_ok=True)\n",
    "                    \n",
    "                    # Save EfficientNet features as .npy file\n",
    "                    efficientnet_features_path = os.path.join(features_output_dir, \"efficientnet_features.npy\")\n",
    "                    \n",
    "                    print(f\"\\nğŸ’¾ Saving EfficientNet features as .npy file...\")\n",
    "                    print(f\"   Output directory: {features_output_dir}\")\n",
    "                    print(f\"   Features file: efficientnet_features.npy\")\n",
    "                    \n",
    "                    try:\n",
    "                        # Save the features array\n",
    "                        np.save(efficientnet_features_path, features_array)\n",
    "                        \n",
    "                        # Verify the saved file\n",
    "                        saved_features = np.load(efficientnet_features_path)\n",
    "                        file_size_mb = os.path.getsize(efficientnet_features_path) / 1024 / 1024\n",
    "                        \n",
    "                        print(f\"\\nâœ… Successfully saved EfficientNet features!\")\n",
    "                        print(f\"   File: efficientnet_features.npy\")\n",
    "                        print(f\"   Shape: {saved_features.shape}\")\n",
    "                        print(f\"   Data type: {saved_features.dtype}\")\n",
    "                        print(f\"   File size: {file_size_mb:.1f} MB\")\n",
    "                        print(f\"   Location: {efficientnet_features_path}\")\n",
    "                        \n",
    "                        # Feature statistics\n",
    "                        print(f\"\\nğŸ“ˆ Feature Statistics:\")\n",
    "                        print(f\"   Mean: {features_array.mean():.6f}\")\n",
    "                        print(f\"   Std:  {features_array.std():.6f}\")\n",
    "                        print(f\"   Min:  {features_array.min():.6f}\")\n",
    "                        print(f\"   Max:  {features_array.max():.6f}\")\n",
    "                        \n",
    "                        # Create metadata file with extraction details\n",
    "                        metadata = {\n",
    "                            \"feature_type\": \"efficientnet_b3\",\n",
    "                            \"model_checkpoint\": checkpoint_path,\n",
    "                            \"extraction_timestamp\": datetime.now().isoformat(),\n",
    "                            \"processing_time\": str(processing_time),\n",
    "                            \"num_images\": len(dataset),\n",
    "                            \"feature_dimension\": features_array.shape[1],\n",
    "                            \"total_features\": features_array.size,\n",
    "                            \"model_info\": checkpoint_info,\n",
    "                            \"image_transforms\": {\n",
    "                                \"resize\": CONFIG['image_size'],\n",
    "                                \"normalize_mean\": [0.485, 0.456, 0.406],\n",
    "                                \"normalize_std\": [0.229, 0.224, 0.225]\n",
    "                            },\n",
    "                            \"statistics\": {\n",
    "                                \"mean\": float(features_array.mean()),\n",
    "                                \"std\": float(features_array.std()),\n",
    "                                \"min\": float(features_array.min()),\n",
    "                                \"max\": float(features_array.max())\n",
    "                            }\n",
    "                        }\n",
    "                        \n",
    "                        # Save metadata as JSON\n",
    "                        metadata_path = os.path.join(features_output_dir, \"efficientnet_features_metadata.json\")\n",
    "                        with open(metadata_path, 'w') as f:\n",
    "                            json.dump(metadata, f, indent=2)\n",
    "                        \n",
    "                        print(f\"\\nğŸ“‹ Metadata saved: efficientnet_features_metadata.json\")\n",
    "                        \n",
    "                        print(f\"\\nğŸ¯ EfficientNet Feature Extraction Pipeline Completed!\")\n",
    "                        print(f\"âœ“ {len(dataset):,} images processed\")\n",
    "                        print(f\"âœ“ {features_array.shape[1]:,} features per image\")\n",
    "                        print(f\"âœ“ {features_array.size:,} total feature values extracted\")\n",
    "                        print(f\"âœ“ Features saved as .npy file (compatible with existing pipeline)\")\n",
    "                        print(f\"âœ“ Ready for downstream ML tasks\")\n",
    "                        \n",
    "                        # Show how to load the features\n",
    "                        print(f\"\\nğŸ“– Usage Example:\")\n",
    "                        print(f\"```python\")\n",
    "                        print(f\"import numpy as np\")\n",
    "                        print(f\"features = np.load('{efficientnet_features_path}')\")\n",
    "                        print(f\"print(f'Loaded features shape: {{features.shape}}')\")\n",
    "                        print(f\"```\")\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"âŒ Error saving features: {e}\")\n",
    "                        print(\"Features are available in 'features_array' variable\")\n",
    "                        import traceback\n",
    "                        traceback.print_exc()\n",
    "                        \n",
    "                else:\n",
    "                    print(\"âŒ No valid images found!\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing metadata: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "else:\n",
    "    print(\"âŒ Model not loaded - cannot perform feature extraction\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65953f24",
   "metadata": {},
   "source": [
    "## ğŸ¯ Summary\n",
    "\n",
    "This notebook successfully:\n",
    "\n",
    "1. **âœ… Loaded pre-trained EfficientNet-B3 model** - Restored from checkpoint with all weights\n",
    "2. **âœ… Performed single image inference** - Tested prediction functionality \n",
    "3. **âœ… Extracted deep features** - Generated 1536-dimensional feature vectors from penultimate layer\n",
    "4. **âœ… Processed full dataset** - Batch inference on entire preprocessed ISIC 2019 dataset\n",
    "5. **âœ… Saved features as .npy files** - Following existing pipeline pattern for feature storage\n",
    "\n",
    "### ğŸ“Š Results\n",
    "- **Dataset size**: ~8,000 skin lesion images\n",
    "- **Features per image**: 1,536 (EfficientNet-B3 penultimate layer)\n",
    "- **Output format**: `.npy` file (NumPy binary format)\n",
    "- **Total feature values**: ~12.3 million\n",
    "- **Compatible**: With existing feature extraction pipeline\n",
    "\n",
    "### ğŸ”„ Next Steps\n",
    "The EfficientNet features can now be used for:\n",
    "- **Similarity search** and clustering\n",
    "- **Transfer learning** for other medical imaging tasks\n",
    "- **Feature analysis** and dimensionality reduction\n",
    "- **Ensemble models** combining deep features with hand-crafted features\n",
    "- **Downstream classification** tasks\n",
    "\n",
    "### ğŸ“ Output Files\n",
    "```\n",
    "../pipeline_output/features/final/isic_2019/\n",
    "â”œâ”€â”€ efficientnet_features.npy          # Main feature array (N Ã— 1536)\n",
    "â””â”€â”€ efficientnet_features_metadata.json # Extraction metadata\n",
    "```\n",
    "\n",
    "### ğŸ’» Usage Example\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Load EfficientNet features\n",
    "features = np.load('../pipeline_output/features/final/isic_2019/efficientnet_features.npy')\n",
    "print(f'Features shape: {features.shape}')  # (N, 1536)\n",
    "\n",
    "# Load other existing features for ensemble\n",
    "color_features = np.load('../pipeline_output/features/final/isic_2019/color_features.npy')\n",
    "glcm_features = np.load('../pipeline_output/features/final/isic_2019/glcm_features.npy')\n",
    "\n",
    "# Combine features\n",
    "combined_features = np.concatenate([features, color_features, glcm_features], axis=1)\n",
    "print(f'Combined features shape: {combined_features.shape}')\n",
    "```\n",
    "\n",
    "The features are now stored in the same directory structure as other extracted features, making them easy to combine and use in downstream machine learning tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

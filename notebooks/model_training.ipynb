{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a60afb3",
   "metadata": {},
   "source": [
    "# VGG16 Transfer Learning for ISIC 2019 Skin Lesion Classification\n",
    "\n",
    "## Medical Image Classification with Deep Learning\n",
    "\n",
    "This notebook implements VGG16 transfer learning for automated skin lesion diagnosis using the ISIC 2019 dataset. It integrates seamlessly with our GPU-optimized preprocessing pipeline.\n",
    "\n",
    "### Key Features:\n",
    "- **GPU-Optimized Training**: Uses pre-augmented images for maximum efficiency\n",
    "- **Transfer Learning**: Leverages VGG16 pre-trained on ImageNet\n",
    "- **Comprehensive Evaluation**: Detailed metrics and visualizations\n",
    "- **Class Balancing**: Handles imbalanced medical data\n",
    "- **Medical Focus**: Optimized for dermatological image analysis\n",
    "\n",
    "### Architecture Overview:\n",
    "```\n",
    "Input (224x224) â†’ VGG16 Features (frozen) â†’ Custom Classifier â†’ 9 Classes\n",
    "                                                 â†‘\n",
    "                                          Extract features from\n",
    "                                          second-to-last layer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af144f3a",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054e1297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Essential imports\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep learning imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms, models\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Add scripts directory to path\n",
    "sys.path.append('../scripts')\n",
    "from data_loader import AzureBlobLoader\n",
    "from image_preprocessor import ImagePreprocessor\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(\"Setup complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003385ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration constants\n",
    "CONFIG = {\n",
    "    'azure_account': 'w281saysxxfypm',\n",
    "    'azure_container': 'isic-2019-data',\n",
    "    'data_dir': '../data',\n",
    "    'images_dir': '../data/isic_images',\n",
    "    'metadata_file': 'ISIC_2019_Training_Metadata.csv',\n",
    "    'ground_truth_file': 'ISIC_2019_Training_GroundTruth.csv',\n",
    "    'num_images': 5000,  # For initial testing\n",
    "    'batch_size': 32,\n",
    "    'num_epochs': 50,\n",
    "    'learning_rate': 0.001,\n",
    "    'weight_decay': 1e-4,\n",
    "    'num_workers': 4,\n",
    "    'patience': 10,  # Early stopping\n",
    "    'validation_split': 0.2,\n",
    "    'test_split': 0.1,\n",
    "    'image_size': 224,  # VGG16 input size\n",
    "    'num_classes': 9,\n",
    "    'class_names': ['MEL', 'NV', 'BCC', 'AK', 'BKL', 'DF', 'VASC', 'SCC', 'UNK']\n",
    "}\n",
    "\n",
    "print(\"Configuration loaded:\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5fc23c",
   "metadata": {},
   "source": [
    "## Data Loading and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data loader and preprocessor\n",
    "data_loader = AzureBlobLoader(CONFIG['azure_account'], CONFIG['azure_container'])\n",
    "preprocessor = ImagePreprocessor()\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(CONFIG['data_dir'], exist_ok=True)\n",
    "os.makedirs(CONFIG['images_dir'], exist_ok=True)\n",
    "\n",
    "# Check if data already exists\n",
    "metadata_path = os.path.join(CONFIG['data_dir'], CONFIG['metadata_file'])\n",
    "ground_truth_path = os.path.join(CONFIG['data_dir'], CONFIG['ground_truth_file'])\n",
    "\n",
    "if not os.path.exists(metadata_path) or not os.path.exists(ground_truth_path):\n",
    "    print(\"Downloading metadata files...\")\n",
    "    # Download metadata\n",
    "    data_loader.download_single_file(CONFIG['metadata_file'], CONFIG['data_dir'])\n",
    "    data_loader.download_single_file(CONFIG['ground_truth_file'], CONFIG['data_dir'])\n",
    "    print(\"Metadata downloaded!\")\n",
    "else:\n",
    "    print(\"Metadata files already exist!\")\n",
    "\n",
    "# Load metadata\n",
    "print(\"Loading metadata...\")\n",
    "metadata_df = pd.read_csv(metadata_path)\n",
    "ground_truth_df = pd.read_csv(ground_truth_path)\n",
    "\n",
    "# Merge metadata with ground truth\n",
    "df = pd.merge(metadata_df, ground_truth_df, on='image')\n",
    "print(f\"Loaded {len(df)} images with metadata\")\n",
    "print(\"\\nDataset columns:\", df.columns.tolist())\n",
    "print(\"\\nClass distribution:\")\n",
    "diagnosis_cols = [col for col in df.columns if col not in ['image', 'age_approx', 'anatom_site_general', 'sex']]\n",
    "for col in diagnosis_cols:\n",
    "    count = df[col].sum()\n",
    "    if count > 0:\n",
    "        print(f\"  {col}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04675805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for training (to speed up development)\n",
    "print(f\"Sampling {CONFIG['num_images']} images for training...\")\n",
    "\n",
    "# Create target column for classification\n",
    "df['target'] = df[diagnosis_cols].idxmax(axis=1)\n",
    "df['target_idx'] = LabelEncoder().fit_transform(df['target'])\n",
    "\n",
    "# Stratified sampling to maintain class distribution\n",
    "from sklearn.model_selection import train_test_split\n",
    "sampled_df, _ = train_test_split(\n",
    "    df, \n",
    "    train_size=CONFIG['num_images'], \n",
    "    stratify=df['target'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Sampled dataset class distribution:\")\n",
    "for i, class_name in enumerate(CONFIG['class_names']):\n",
    "    count = (sampled_df['target_idx'] == i).sum()\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "# Check which images need to be downloaded\n",
    "existing_images = set()\n",
    "if os.path.exists(CONFIG['images_dir']):\n",
    "    existing_images = set(os.listdir(CONFIG['images_dir']))\n",
    "    existing_images = {img.replace('.jpg', '') for img in existing_images if img.endswith('.jpg')}\n",
    "\n",
    "images_to_download = []\n",
    "for image_id in sampled_df['image']:\n",
    "    if image_id not in existing_images:\n",
    "        images_to_download.append(image_id)\n",
    "\n",
    "print(f\"Found {len(existing_images)} existing images\")\n",
    "print(f\"Need to download {len(images_to_download)} new images\")\n",
    "\n",
    "# Download missing images\n",
    "if images_to_download:\n",
    "    print(\"â³ Downloading images... This may take a while.\")\n",
    "    success_count, error_count = data_loader.download_images_batch(\n",
    "        images_to_download, \n",
    "        CONFIG['images_dir']\n",
    "    )\n",
    "    print(f\"Downloaded {success_count} images, {error_count} errors\")\n",
    "else:\n",
    "    print(\"All required images already downloaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be83f2e",
   "metadata": {},
   "source": [
    "## Custom Dataset and Data Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a86e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinLesionDataset(Dataset):\n",
    "    \"\"\"Custom dataset for skin lesion images with advanced preprocessing\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, images_dir, transform=None, preprocessing=True):\n",
    "        self.df = dataframe.reset_index(drop=True)\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.preprocessing = preprocessing\n",
    "        self.preprocessor = ImagePreprocessor()\n",
    "        \n",
    "        # Filter only images that exist\n",
    "        self.df = self._filter_existing_images()\n",
    "        print(f\"Dataset initialized with {len(self.df)} valid images\")\n",
    "    \n",
    "    def _filter_existing_images(self):\n",
    "        \"\"\"Filter dataframe to only include images that exist on disk\"\"\"\n",
    "        existing_images = []\n",
    "        for idx, row in self.df.iterrows():\n",
    "            image_path = os.path.join(self.images_dir, f\"{row['image']}.jpg\")\n",
    "            if os.path.exists(image_path):\n",
    "                existing_images.append(row)\n",
    "        \n",
    "        if existing_images:\n",
    "            return pd.DataFrame(existing_images).reset_index(drop=True)\n",
    "        else:\n",
    "            return pd.DataFrame()\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Get image info\n",
    "        row = self.df.iloc[idx]\n",
    "        image_id = row['image']\n",
    "        label = row['target_idx']\n",
    "        \n",
    "        # Load image\n",
    "        image_path = os.path.join(self.images_dir, f\"{image_id}.jpg\")\n",
    "        \n",
    "        try:\n",
    "            from PIL import Image\n",
    "            image = Image.open(image_path).convert('RGB')\n",
    "            \n",
    "            # Apply custom preprocessing if enabled\n",
    "            if self.preprocessing:\n",
    "                # Convert PIL to numpy for preprocessing\n",
    "                image_np = np.array(image)\n",
    "                \n",
    "                # Apply vignette detection and circular cropping\n",
    "                processed_image = self.preprocessor.detect_circular_vignette(image_np)\n",
    "                \n",
    "                # Convert back to PIL\n",
    "                image = Image.fromarray(processed_image.astype(np.uint8))\n",
    "            \n",
    "            # Apply transforms\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            \n",
    "            return image, label, image_id\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_id}: {e}\")\n",
    "            # Return a black image as fallback\n",
    "            if self.transform:\n",
    "                black_image = self.transform(Image.new('RGB', (224, 224), (0, 0, 0)))\n",
    "            else:\n",
    "                black_image = torch.zeros(3, 224, 224)\n",
    "            return black_image, label, image_id\n",
    "\n",
    "print(\"SkinLesionDataset class defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fc16d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms optimized for medical images\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=20),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet normalization\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((CONFIG['image_size'], CONFIG['image_size'])),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "print(\"Data transforms defined!\")\n",
    "print(\"Training transforms include:\")\n",
    "print(\"  - Resize to 224x224\")\n",
    "print(\"  - Random horizontal/vertical flips\")\n",
    "print(\"  - Random rotation (Â±20Â°)\")\n",
    "print(\"  - Color jittering\")\n",
    "print(\"  - Random affine transformations\")\n",
    "print(\"  - ImageNet normalization\")\n",
    "print(\"\\nValidation transforms include:\")\n",
    "print(\"  - Resize to 224x224\")\n",
    "print(\"  - ImageNet normalization only\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6d7dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/validation/test splits\n",
    "print(\"Creating train/validation/test splits...\")\n",
    "\n",
    "# First split: separate test set\n",
    "train_val_df, test_df = train_test_split(\n",
    "    sampled_df, \n",
    "    test_size=CONFIG['test_split'], \n",
    "    stratify=sampled_df['target_idx'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Second split: separate train and validation\n",
    "train_df, val_df = train_test_split(\n",
    "    train_val_df, \n",
    "    test_size=CONFIG['validation_split']/(1-CONFIG['test_split']), \n",
    "    stratify=train_val_df['target_idx'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Dataset splits:\")\n",
    "print(f\"  Training: {len(train_df)} images\")\n",
    "print(f\"  Validation: {len(val_df)} images\")\n",
    "print(f\"  Test: {len(test_df)} images\")\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = SkinLesionDataset(train_df, CONFIG['images_dir'], train_transforms, preprocessing=True)\n",
    "val_dataset = SkinLesionDataset(val_df, CONFIG['images_dir'], val_transforms, preprocessing=True)\n",
    "test_dataset = SkinLesionDataset(test_df, CONFIG['images_dir'], val_transforms, preprocessing=True)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=True, \n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=CONFIG['batch_size'], \n",
    "    shuffle=False, \n",
    "    num_workers=CONFIG['num_workers'],\n",
    "    pin_memory=True if device.type == 'cuda' else False\n",
    ")\n",
    "\n",
    "print(f\"Data loaders created!\")\n",
    "print(f\"Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"Number of workers: {CONFIG['num_workers']}\")\n",
    "print(f\"Pin memory: {device.type == 'cuda'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41778dd2",
   "metadata": {},
   "source": [
    "## Data Visualization and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa101446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "datasets = [('Training', train_df), ('Validation', val_df), ('Test', test_df)]\n",
    "colors = plt.cm.Set3(np.linspace(0, 1, len(CONFIG['class_names'])))\n",
    "\n",
    "for idx, (name, df) in enumerate(datasets):\n",
    "    class_counts = [sum(df['target_idx'] == i) for i in range(len(CONFIG['class_names']))]\n",
    "    \n",
    "    axes[idx].bar(CONFIG['class_names'], class_counts, color=colors)\n",
    "    axes[idx].set_title(f'{name} Set Class Distribution')\n",
    "    axes[idx].set_xlabel('Diagnosis')\n",
    "    axes[idx].set_ylabel('Count')\n",
    "    axes[idx].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, count in enumerate(class_counts):\n",
    "        axes[idx].text(i, count + 0.5, str(count), ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate class weights for handling imbalanced data\n",
    "class_counts = np.bincount(train_df['target_idx'])\n",
    "class_weights = compute_class_weight('balanced', classes=np.arange(len(CONFIG['class_names'])), y=train_df['target_idx'])\n",
    "class_weights_tensor = torch.FloatTensor(class_weights).to(device)\n",
    "\n",
    "print(\"âš–ï¸ Class weights for balanced training:\")\n",
    "for i, (name, weight) in enumerate(zip(CONFIG['class_names'], class_weights)):\n",
    "    print(f\"  {name}: {weight:.3f} (count: {class_counts[i]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6f7047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images from each class\n",
    "def denormalize(tensor):\n",
    "    \"\"\"Denormalize tensor for visualization\"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1)\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1)\n",
    "    return tensor * std + mean\n",
    "\n",
    "def show_sample_images():\n",
    "    \"\"\"Display sample images from each diagnostic class\"\"\"\n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Get one sample from each class\n",
    "    for class_idx in range(min(9, len(CONFIG['class_names']))):\n",
    "        class_samples = train_df[train_df['target_idx'] == class_idx]\n",
    "        if len(class_samples) > 0:\n",
    "            # Get random sample\n",
    "            sample_idx = np.random.randint(0, len(class_samples))\n",
    "            sample_row = class_samples.iloc[sample_idx]\n",
    "            \n",
    "            # Load and process image\n",
    "            image_path = os.path.join(CONFIG['images_dir'], f\"{sample_row['image']}.jpg\")\n",
    "            if os.path.exists(image_path):\n",
    "                from PIL import Image\n",
    "                image = Image.open(image_path).convert('RGB')\n",
    "                \n",
    "                # Apply preprocessing and transforms\n",
    "                preprocessor = ImagePreprocessor()\n",
    "                image_np = np.array(image)\n",
    "                processed_image = preprocessor.detect_circular_vignette(image_np)\n",
    "                image_pil = Image.fromarray(processed_image.astype(np.uint8))\n",
    "                \n",
    "                # Apply validation transforms (no augmentation)\n",
    "                image_tensor = val_transforms(image_pil)\n",
    "                \n",
    "                # Denormalize for display\n",
    "                display_image = denormalize(image_tensor)\n",
    "                display_image = torch.clamp(display_image, 0, 1)\n",
    "                \n",
    "                # Convert to numpy and transpose for matplotlib\n",
    "                display_image = display_image.permute(1, 2, 0).numpy()\n",
    "                \n",
    "                axes[class_idx].imshow(display_image)\n",
    "                axes[class_idx].set_title(f'{CONFIG[\"class_names\"][class_idx]}\\n({sample_row[\"image\"]})')\n",
    "                axes[class_idx].axis('off')\n",
    "            else:\n",
    "                axes[class_idx].text(0.5, 0.5, f'{CONFIG[\"class_names\"][class_idx]}\\nImage not found', \n",
    "                                   ha='center', va='center', transform=axes[class_idx].transAxes)\n",
    "                axes[class_idx].axis('off')\n",
    "        else:\n",
    "            axes[class_idx].text(0.5, 0.5, f'{CONFIG[\"class_names\"][class_idx]}\\nNo samples', \n",
    "                               ha='center', va='center', transform=axes[class_idx].transAxes)\n",
    "            axes[class_idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Sample Images from Each Diagnostic Class (After Preprocessing)', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_sample_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34cd78",
   "metadata": {},
   "source": [
    "## VGG16 Transfer Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae326f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16SkinLesionClassifier(nn.Module):\n",
    "    \"\"\"VGG16-based transfer learning model for skin lesion classification\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes=9, pretrained=True, freeze_features=True, dropout_rate=0.5):\n",
    "        super(VGG16SkinLesionClassifier, self).__init__()\n",
    "        \n",
    "        # Load pretrained VGG16\n",
    "        self.vgg16 = models.vgg16(pretrained=pretrained)\n",
    "        \n",
    "        # Freeze feature extraction layers if specified\n",
    "        if freeze_features:\n",
    "            for param in self.vgg16.features.parameters():\n",
    "                param.requires_grad = False\n",
    "            print(\"VGG16 feature layers frozen\")\n",
    "        else:\n",
    "            print(\"VGG16 feature layers unfrozen\")\n",
    "        \n",
    "        # Get number of features from the last layer before classifier\n",
    "        num_features = self.vgg16.classifier[6].in_features\n",
    "        \n",
    "        # Replace the classifier with our custom one\n",
    "        self.vgg16.classifier = nn.Sequential(\n",
    "            nn.Linear(25088, 4096),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(4096, 2048),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(2048, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Store feature extractor (all layers except the final classifier)\n",
    "        self.feature_extractor = nn.Sequential(*list(self.vgg16.children())[:-1])\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        \n",
    "        self.num_classes = num_classes\n",
    "        self.dropout_rate = dropout_rate\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        return self.vgg16(x)\n",
    "    \n",
    "    def extract_features(self, x):\n",
    "        \"\"\"Extract features from the second-to-last layer\"\"\"\n",
    "        # Pass through feature extraction layers\n",
    "        x = self.vgg16.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        \n",
    "        # Pass through classifier layers except the last one\n",
    "        classifier_layers = list(self.vgg16.classifier.children())[:-1]\n",
    "        for layer in classifier_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_model_summary(self):\n",
    "        \"\"\"Print model architecture summary\"\"\"\n",
    "        total_params = sum(p.numel() for p in self.parameters())\n",
    "        trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "        \n",
    "        print(\"VGG16 Skin Lesion Classifier Architecture:\")\n",
    "        print(f\"  Total parameters: {total_params:,}\")\n",
    "        print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "        print(f\"  Frozen parameters: {total_params - trainable_params:,}\")\n",
    "        print(f\"  Dropout rate: {self.dropout_rate}\")\n",
    "        print(f\"  Number of classes: {self.num_classes}\")\n",
    "        \n",
    "        return total_params, trainable_params\n",
    "\n",
    "# Create model\n",
    "model = VGG16SkinLesionClassifier(\n",
    "    num_classes=CONFIG['num_classes'],\n",
    "    pretrained=True,\n",
    "    freeze_features=True,\n",
    "    dropout_rate=0.5\n",
    ")\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(device)\n",
    "\n",
    "# Get model summary\n",
    "total_params, trainable_params = model.get_model_summary()\n",
    "\n",
    "print(f\"\\nModel loaded on: {device}\")\n",
    "print(\"VGG16 Transfer Learning Model created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81360a60",
   "metadata": {},
   "source": [
    "## Training Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29ea7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss function with class weights for imbalanced data\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights_tensor)\n",
    "\n",
    "# Optimizer - Adam with weight decay\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=CONFIG['learning_rate'],\n",
    "    weight_decay=CONFIG['weight_decay']\n",
    ")\n",
    "\n",
    "# Learning rate scheduler - reduce on plateau\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,\n",
    "    patience=5,\n",
    "    verbose=True,\n",
    "    min_lr=1e-7\n",
    ")\n",
    "\n",
    "# Early stopping setup\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, min_delta=0, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        if self.counter >= self.patience:\n",
    "            if self.restore_best_weights:\n",
    "                model.load_state_dict(self.best_weights)\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        self.best_weights = model.state_dict().copy()\n",
    "\n",
    "early_stopping = EarlyStopping(patience=CONFIG['patience'])\n",
    "\n",
    "print(\"Training setup complete!\")\n",
    "print(f\"Loss function: CrossEntropyLoss with class weights\")\n",
    "print(f\"Optimizer: Adam (lr={CONFIG['learning_rate']}, wd={CONFIG['weight_decay']})\")\n",
    "print(f\"Scheduler: ReduceLROnPlateau (factor=0.5, patience=5)\")\n",
    "print(f\"Early stopping: Patience={CONFIG['patience']} epochs\")\n",
    "print(f\"Max epochs: {CONFIG['num_epochs']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96feaf5",
   "metadata": {},
   "source": [
    "## Training Loop Implementation\n",
    "\n",
    "The following training loop includes:\n",
    "- **Comprehensive metrics tracking**: Accuracy, precision, recall, F1-score per class\n",
    "- **GPU optimization**: Efficient batch processing with mixed precision support\n",
    "- **Medical image specific validation**: Class-wise performance monitoring\n",
    "- **Robust checkpointing**: Save best models and training state\n",
    "- **Advanced visualization**: Real-time training progress and confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b3cce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch):\n",
    "    \"\"\"Train for one epoch with detailed metrics\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    \n",
    "    # Progress tracking\n",
    "    batch_losses = []\n",
    "    \n",
    "    for batch_idx, (images, targets, image_ids) in enumerate(train_loader):\n",
    "        images, targets = images.to(device), targets.to(device)\n",
    "        \n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistics\n",
    "        running_loss += loss.item()\n",
    "        batch_losses.append(loss.item())\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "        \n",
    "        # Store for detailed metrics\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "        \n",
    "        # Print progress every 20 batches\n",
    "        if batch_idx % 20 == 0 and batch_idx > 0:\n",
    "            avg_loss = running_loss / (batch_idx + 1)\n",
    "            accuracy = 100. * correct / total\n",
    "            print(f'  Batch {batch_idx}/{len(train_loader)}: Loss: {avg_loss:.4f}, Acc: {accuracy:.2f}%')\n",
    "    \n",
    "    # Calculate final metrics\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_predictions, all_targets\n",
    "\n",
    "def validate_epoch(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate for one epoch with detailed metrics\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in val_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            # Get probabilities\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            \n",
    "            # Statistics\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += targets.size(0)\n",
    "            correct += (predicted == targets).sum().item()\n",
    "            \n",
    "            # Store for detailed metrics\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    epoch_loss = running_loss / len(val_loader)\n",
    "    epoch_acc = 100. * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc, all_predictions, all_targets, all_probabilities\n",
    "\n",
    "print(\"Training and validation functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae79e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_detailed_metrics(predictions, targets, class_names):\n",
    "    \"\"\"Calculate and display detailed classification metrics\"\"\"\n",
    "    from sklearn.metrics import classification_report, confusion_matrix\n",
    "    \n",
    "    # Classification report\n",
    "    report = classification_report(targets, predictions, target_names=class_names, output_dict=True)\n",
    "    \n",
    "    # Print formatted report\n",
    "    print(\"\\nDetailed Classification Metrics:\")\n",
    "    print(\"=\" * 60)\n",
    "    for class_name in class_names:\n",
    "        if class_name in report:\n",
    "            metrics = report[class_name]\n",
    "            print(f\"{class_name:>8}: P={metrics['precision']:.3f}, R={metrics['recall']:.3f}, F1={metrics['f1-score']:.3f}, Support={int(metrics['support'])}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "    print(f\"{'Accuracy':>8}: {report['accuracy']:.3f}\")\n",
    "    print(f\"{'Macro Avg':>8}: P={report['macro avg']['precision']:.3f}, R={report['macro avg']['recall']:.3f}, F1={report['macro avg']['f1-score']:.3f}\")\n",
    "    print(f\"{'Weighted Avg':>8}: P={report['weighted avg']['precision']:.3f}, R={report['weighted avg']['recall']:.3f}, F1={report['weighted avg']['f1-score']:.3f}\")\n",
    "    \n",
    "    return report\n",
    "\n",
    "def plot_confusion_matrix(predictions, targets, class_names, title=\"Confusion Matrix\"):\n",
    "    \"\"\"Plot confusion matrix with medical focus\"\"\"\n",
    "    cm = confusion_matrix(targets, predictions)\n",
    "    \n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f'{title}\\n(Medical Image Classification)', fontsize=14)\n",
    "    plt.xlabel('Predicted Diagnosis', fontsize=12)\n",
    "    plt.ylabel('True Diagnosis', fontsize=12)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=0)\n",
    "    \n",
    "    # Add accuracy for each class\n",
    "    class_accuracies = cm.diagonal() / cm.sum(axis=1)\n",
    "    for i, acc in enumerate(class_accuracies):\n",
    "        plt.text(len(class_names) + 0.1, i + 0.5, f'Acc: {acc:.2f}', \n",
    "                va='center', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return cm\n",
    "\n",
    "def plot_training_history(train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"Plot training history with medical context\"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    ax1.plot(epochs, train_losses, 'b-', label='Training Loss', linewidth=2)\n",
    "    ax1.plot(epochs, val_losses, 'r-', label='Validation Loss', linewidth=2)\n",
    "    ax1.set_title('Model Loss (Medical Image Classification)', fontsize=14)\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    ax2.plot(epochs, train_accs, 'b-', label='Training Accuracy', linewidth=2)\n",
    "    ax2.plot(epochs, val_accs, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "    ax2.set_title('Model Accuracy (Skin Lesion Diagnosis)', fontsize=14)\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Metrics and visualization functions defined!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb064b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop with comprehensive monitoring\n",
    "def train_model():\n",
    "    \"\"\"Complete training loop with medical image focus\"\"\"\n",
    "    print(\"Starting VGG16 Transfer Learning Training for Skin Lesion Classification\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Training history\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    \n",
    "    best_val_acc = 0.0\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    for epoch in range(CONFIG['num_epochs']):\n",
    "        epoch_start = datetime.now()\n",
    "        print(f\"\\nEpoch {epoch+1}/{CONFIG['num_epochs']}\")\n",
    "        print(\"-\" * 50)\n",
    "        \n",
    "        # Training phase\n",
    "        print(\"ðŸ“š Training phase...\")\n",
    "        train_loss, train_acc, train_preds, train_targets = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, device, epoch+1\n",
    "        )\n",
    "        \n",
    "        # Validation phase\n",
    "        print(\"Validation phase...\")\n",
    "        val_loss, val_acc, val_preds, val_targets, val_probs = validate_epoch(\n",
    "            model, val_loader, criterion, device\n",
    "        )\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        \n",
    "        # Store history\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        # Calculate epoch time\n",
    "        epoch_time = datetime.now() - epoch_start\n",
    "        \n",
    "        # Print epoch summary\n",
    "        print(f\"\\nEpoch {epoch+1} Summary:\")\n",
    "        print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.2f}%\")\n",
    "        print(f\"  Learning Rate: {current_lr:.2e}\")\n",
    "        print(f\"  Time: {epoch_time.total_seconds():.1f}s\")\n",
    "        \n",
    "        # Check if best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            print(f\"  New best validation accuracy: {best_val_acc:.2f}%\")\n",
    "            \n",
    "            # Save best model (we'll implement this next)\n",
    "            best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        # Early stopping check\n",
    "        if early_stopping(val_loss, model):\n",
    "            print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "            break\n",
    "        \n",
    "        # Show detailed metrics every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"\\nDetailed Validation Metrics (Epoch {epoch+1}):\")\n",
    "            calculate_detailed_metrics(val_preds, val_targets, CONFIG['class_names'])\n",
    "    \n",
    "    # Training complete\n",
    "    total_time = datetime.now() - start_time\n",
    "    print(f\"\\nðŸ Training Complete!\")\n",
    "    print(f\"Total time: {total_time}\")\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(train_losses, val_losses, train_accs, val_accs)\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'total_time': total_time\n",
    "    }\n",
    "\n",
    "print(\"Main training function defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9994ae4",
   "metadata": {},
   "source": [
    "## Model Evaluation and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dcbbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_comprehensive(model, test_loader, device, class_names):\n",
    "    \"\"\"Comprehensive model evaluation with medical focus\"\"\"\n",
    "    print(\"Comprehensive Model Evaluation\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    model.eval()\n",
    "    all_predictions = []\n",
    "    all_targets = []\n",
    "    all_probabilities = []\n",
    "    all_image_ids = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in test_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store results\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "            all_image_ids.extend(image_ids)\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    print(f\"Overall Test Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    # Detailed metrics\n",
    "    print(\"\\nDetailed Classification Report:\")\n",
    "    report = calculate_detailed_metrics(all_predictions, all_targets, class_names)\n",
    "    \n",
    "    # Confusion matrix\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    cm = plot_confusion_matrix(all_predictions, all_targets, class_names, \"Test Set Confusion Matrix\")\n",
    "    \n",
    "    # Per-class analysis\n",
    "    print(\"\\nPer-Class Performance Analysis:\")\n",
    "    for i, class_name in enumerate(class_names):\n",
    "        class_mask = np.array(all_targets) == i\n",
    "        if np.sum(class_mask) > 0:\n",
    "            class_predictions = np.array(all_predictions)[class_mask]\n",
    "            class_accuracy = accuracy_score(np.array(all_targets)[class_mask], class_predictions)\n",
    "            print(f\"  {class_name}: {class_accuracy*100:.1f}% accuracy ({np.sum(class_mask)} samples)\")\n",
    "    \n",
    "    # Most confident predictions\n",
    "    confidence_scores = np.max(all_probabilities, axis=1)\n",
    "    correct_predictions = np.array(all_predictions) == np.array(all_targets)\n",
    "    \n",
    "    print(f\"\\nConfidence Analysis:\")\n",
    "    print(f\"  Average confidence: {np.mean(confidence_scores):.3f}\")\n",
    "    print(f\"  Confidence on correct predictions: {np.mean(confidence_scores[correct_predictions]):.3f}\")\n",
    "    print(f\"  Confidence on incorrect predictions: {np.mean(confidence_scores[~correct_predictions]):.3f}\")\n",
    "    \n",
    "    return {\n",
    "        'predictions': all_predictions,\n",
    "        'targets': all_targets,\n",
    "        'probabilities': all_probabilities,\n",
    "        'image_ids': all_image_ids,\n",
    "        'accuracy': accuracy,\n",
    "        'report': report,\n",
    "        'confusion_matrix': cm\n",
    "    }\n",
    "\n",
    "def analyze_misclassifications(model, test_loader, device, class_names, num_samples=9):\n",
    "    \"\"\"Analyze and visualize misclassified samples\"\"\"\n",
    "    print(\"Misclassification Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    model.eval()\n",
    "    misclassified_samples = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, targets, image_ids in test_loader:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            probabilities = F.softmax(outputs, dim=1)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Find misclassified samples\n",
    "            incorrect_mask = predicted != targets\n",
    "            if incorrect_mask.any():\n",
    "                for i in range(len(images)):\n",
    "                    if incorrect_mask[i]:\n",
    "                        misclassified_samples.append({\n",
    "                            'image': images[i].cpu(),\n",
    "                            'true_label': targets[i].item(),\n",
    "                            'pred_label': predicted[i].item(),\n",
    "                            'probabilities': probabilities[i].cpu().numpy(),\n",
    "                            'image_id': image_ids[i]\n",
    "                        })\n",
    "            \n",
    "            if len(misclassified_samples) >= num_samples:\n",
    "                break\n",
    "    \n",
    "    # Visualize misclassifications\n",
    "    if misclassified_samples:\n",
    "        fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i, sample in enumerate(misclassified_samples[:num_samples]):\n",
    "            # Denormalize image\n",
    "            img = denormalize(sample['image'])\n",
    "            img = torch.clamp(img, 0, 1)\n",
    "            img = img.permute(1, 2, 0).numpy()\n",
    "            \n",
    "            # Plot\n",
    "            axes[i].imshow(img)\n",
    "            true_class = class_names[sample['true_label']]\n",
    "            pred_class = class_names[sample['pred_label']]\n",
    "            confidence = sample['probabilities'][sample['pred_label']]\n",
    "            \n",
    "            axes[i].set_title(f'True: {true_class}\\nPred: {pred_class} ({confidence:.2f})\\nID: {sample[\"image_id\"]}')\n",
    "            axes[i].axis('off')\n",
    "        \n",
    "        plt.suptitle('Misclassified Samples Analysis', fontsize=16)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Analyzed {len(misclassified_samples[:num_samples])} misclassified samples\")\n",
    "    else:\n",
    "        print(\"No misclassifications found in the sample!\")\n",
    "\n",
    "print(\"Evaluation functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7313c5",
   "metadata": {},
   "source": [
    "## Model Saving and Loading Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24e028d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_checkpoint(model, optimizer, scheduler, epoch, val_acc, val_loss, config, filename=None):\n",
    "    \"\"\"Save complete model checkpoint with metadata\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"vgg16_skinlesion_epoch_{epoch}_acc_{val_acc:.2f}_{timestamp}.pth\"\n",
    "    \n",
    "    # Create models directory\n",
    "    models_dir = \"../models\"\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    filepath = os.path.join(models_dir, filename)\n",
    "    \n",
    "    # Prepare checkpoint data\n",
    "    checkpoint = {\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'scheduler_state_dict': scheduler.state_dict(),\n",
    "        'val_accuracy': val_acc,\n",
    "        'val_loss': val_loss,\n",
    "        'config': config,\n",
    "        'class_names': CONFIG['class_names'],\n",
    "        'model_architecture': 'VGG16SkinLesionClassifier',\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'device': str(device)\n",
    "    }\n",
    "    \n",
    "    # Save checkpoint\n",
    "    torch.save(checkpoint, filepath)\n",
    "    print(f\"Model checkpoint saved: {filename}\")\n",
    "    print(f\"   Epoch: {epoch}, Val Acc: {val_acc:.2f}%, Val Loss: {val_loss:.4f}\")\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "def load_model_checkpoint(filepath, model, optimizer=None, scheduler=None):\n",
    "    \"\"\"Load model checkpoint with full state restoration\"\"\"\n",
    "    print(f\"Loading model checkpoint: {filepath}\")\n",
    "    \n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(filepath, map_location=device)\n",
    "    \n",
    "    # Restore model state\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    # Restore optimizer and scheduler if provided\n",
    "    if optimizer and 'optimizer_state_dict' in checkpoint:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    \n",
    "    if scheduler and 'scheduler_state_dict' in checkpoint:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "    \n",
    "    # Print checkpoint info\n",
    "    print(f\"Checkpoint loaded successfully!\")\n",
    "    print(f\"   Epoch: {checkpoint['epoch']}\")\n",
    "    print(f\"   Validation Accuracy: {checkpoint['val_accuracy']:.2f}%\")\n",
    "    print(f\"   Validation Loss: {checkpoint['val_loss']:.4f}\")\n",
    "    print(f\"   Saved on: {checkpoint['timestamp']}\")\n",
    "    \n",
    "    return checkpoint\n",
    "\n",
    "def save_training_results(training_history, evaluation_results, filename=None):\n",
    "    \"\"\"Save complete training and evaluation results\"\"\"\n",
    "    if filename is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"training_results_{timestamp}.pkl\"\n",
    "    \n",
    "    results_dir = \"../results\"\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    filepath = os.path.join(results_dir, filename)\n",
    "    \n",
    "    # Combine all results\n",
    "    complete_results = {\n",
    "        'training_history': training_history,\n",
    "        'evaluation_results': evaluation_results,\n",
    "        'config': CONFIG,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'model_type': 'VGG16SkinLesionClassifier'\n",
    "    }\n",
    "    \n",
    "    # Save results\n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(complete_results, f)\n",
    "    \n",
    "    print(f\"Training results saved: {filename}\")\n",
    "    return filepath\n",
    "\n",
    "def export_model_for_inference(model, filepath=None):\n",
    "    \"\"\"Export optimized model for inference\"\"\"\n",
    "    if filepath is None:\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filepath = f\"../models/vgg16_skinlesion_inference_{timestamp}.pth\"\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Create inference package\n",
    "    inference_package = {\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'class_names': CONFIG['class_names'],\n",
    "        'num_classes': CONFIG['num_classes'],\n",
    "        'image_size': CONFIG['image_size'],\n",
    "        'transforms': {\n",
    "            'mean': [0.485, 0.456, 0.406],\n",
    "            'std': [0.229, 0.224, 0.225]\n",
    "        },\n",
    "        'model_type': 'VGG16SkinLesionClassifier',\n",
    "        'export_timestamp': datetime.now().isoformat()\n",
    "    }\n",
    "    \n",
    "    torch.save(inference_package, filepath)\n",
    "    print(f\"Inference model exported: {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "print(\"Model saving and loading utilities defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce00386",
   "metadata": {},
   "source": [
    "## Execute Training and Evaluation\n",
    "\n",
    "Ready to train your VGG16 model! The cells below will:\n",
    "\n",
    "1. **Start the training process** with comprehensive monitoring\n",
    "2. **Evaluate the trained model** on the test set\n",
    "3. **Save the best model** and training results\n",
    "4. **Analyze performance** with detailed medical image metrics\n",
    "\n",
    "**Note**: Training may take 30-60 minutes depending on your GPU. The notebook includes early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bcebc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training process\n",
    "print(\"ISIC 2019 Skin Lesion Classification Training\")\n",
    "print(\"Model: VGG16 Transfer Learning\")\n",
    "print(f\"Dataset: {len(train_dataset)} train, {len(val_dataset)} val, {len(test_dataset)} test\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Execute training\n",
    "training_history = train_model()\n",
    "\n",
    "# Save the best model after training\n",
    "print(\"\\nSaving best model...\")\n",
    "best_checkpoint_path = save_model_checkpoint(\n",
    "    model, optimizer, scheduler, \n",
    "    epoch=len(training_history['train_losses']), \n",
    "    val_acc=training_history['best_val_acc'], \n",
    "    val_loss=min(training_history['val_losses']),\n",
    "    config=CONFIG,\n",
    "    filename=\"vgg16_skinlesion_best_model.pth\"\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining completed!\")\n",
    "print(f\"Best validation accuracy: {training_history['best_val_acc']:.2f}%\")\n",
    "print(f\"Total training time: {training_history['total_time']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9105d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive model evaluation on test set\n",
    "print(\"\\nStarting Comprehensive Model Evaluation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "evaluation_results = evaluate_model_comprehensive(\n",
    "    model, test_loader, device, CONFIG['class_names']\n",
    ")\n",
    "\n",
    "# Analyze misclassifications\n",
    "print(\"\\nAnalyzing Misclassifications...\")\n",
    "analyze_misclassifications(model, test_loader, device, CONFIG['class_names'])\n",
    "\n",
    "# Save complete results\n",
    "results_path = save_training_results(training_history, evaluation_results)\n",
    "\n",
    "# Export model for inference\n",
    "inference_model_path = export_model_for_inference(model)\n",
    "\n",
    "print(f\"\\nComplete Evaluation Finished!\")\n",
    "print(f\"Test Accuracy: {evaluation_results['accuracy']*100:.2f}%\")\n",
    "print(f\"Results saved to: {results_path}\")\n",
    "print(f\"Inference model: {inference_model_path}\")\n",
    "\n",
    "# Feature extraction example\n",
    "print(f\"\\nFeature Extraction Capability:\")\n",
    "print(\"The model can extract 512-dimensional features from the second-to-last layer.\")\n",
    "print(\"Use model.extract_features(images) for feature extraction.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b552ba02",
   "metadata": {},
   "source": [
    "## Training Complete - Summary and Next Steps\n",
    "\n",
    "### What We Accomplished:\n",
    "\n",
    "**Complete VGG16 Transfer Learning Pipeline**\n",
    "- Implemented medical-image optimized data preprocessing\n",
    "- Created balanced training with class weights for imbalanced data\n",
    "- Integrated with our GPU-optimized Azure pipeline\n",
    "- Added comprehensive evaluation metrics\n",
    "\n",
    "**Advanced Model Architecture**\n",
    "- VGG16 backbone with frozen feature layers\n",
    "- Custom classifier head optimized for 9-class skin lesion diagnosis\n",
    "- Feature extraction capability from second-to-last layer\n",
    "- Dropout regularization and early stopping\n",
    "\n",
    "**Production-Ready Training Infrastructure**\n",
    "- Automated checkpoint saving and loading\n",
    "- Real-time training visualization and monitoring\n",
    "- Comprehensive evaluation with confusion matrices\n",
    "- Export functionality for deployment\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Model Optimization**: Fine-tune hyperparameters based on results\n",
    "2. **Feature Analysis**: Use extracted features for additional ML models\n",
    "3. **Deployment**: Deploy model using Azure Container Apps\n",
    "4. **Clinical Validation**: Test on additional medical image datasets\n",
    "\n",
    "### Generated Files:\n",
    "- `../models/vgg16_skinlesion_best_model.pth` - Best trained model\n",
    "- `../models/vgg16_skinlesion_inference_*.pth` - Inference-ready model\n",
    "- `../results/training_results_*.pkl` - Complete training history and metrics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
